{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "! pip install pypdfium2 PyMuPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "import pypdfium2 as pdfium\n",
        "import fitz  # PyMuPDF\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import urllib.parse\n",
        "from typing import List, Tuple\n",
        "from datetime import datetime\n",
        "\n",
        "# FLEXIBLE PARAMETER PARSING - HANDLES SINGLE FILE OR ALL FILES\n",
        "# Parameters: input_stage (arg 0), output_stage (arg 1), file_name (arg 2+, optional)\n",
        "# Files with spaces like 'akasha july 2025.pdf' are handled correctly\n",
        "# Default values are provided for testing/development\n",
        "\n",
        "# Set default values\n",
        "input_stage = \"@ADVANCED_ANALYTICS.REDACT_PDF_DEMO.ORIG_PDFS\"\n",
        "output_stage = \"@ADVANCED_ANALYTICS.REDACT_PDF_DEMO.REDACTED_PDFS\"\n",
        "specific_file = None  # None means process all files\n",
        "process_all_files = True  # Default to processing all files\n",
        "\n",
        "# ========================================\n",
        "# FLEXIBLE PARAMETER PARSING\n",
        "# ========================================\n",
        "print(f\"üîç FLEXIBLE PARAMETER DEBUGGING & EXTRACTION:\")\n",
        "print(f\"   Total sys.argv length: {len(sys.argv)}\")\n",
        "print(f\"   Raw sys.argv: {sys.argv}\")\n",
        "print(f\"   Individual arguments:\")\n",
        "for i, arg in enumerate(sys.argv):\n",
        "    print(f\"     sys.argv[{i}] = '{arg}'\")\n",
        "\n",
        "# Parse parameters based on count\n",
        "if len(sys.argv) >= 2:  # At least input_stage and output_stage\n",
        "    try:\n",
        "        print(f\"\\nüìã Parsing parameters from sys.argv...\")\n",
        "        \n",
        "        # Position 1: input_stage\n",
        "        input_stage = sys.argv[0]\n",
        "        print(f\"   ‚úÖ Set input_stage from sys.argv[0] = '{input_stage}'\")\n",
        "        \n",
        "        # Position 2: output_stage  \n",
        "        output_stage = sys.argv[1]\n",
        "        print(f\"   ‚úÖ Set output_stage from sys.argv[1] = '{output_stage}'\")\n",
        "        \n",
        "        # Position 3+: file_name (optional, may contain spaces)\n",
        "        if len(sys.argv) >= 3:\n",
        "            # Everything from position 2 onwards is part of the filename\n",
        "            file_parts = sys.argv[2:]\n",
        "            specific_file = \" \".join(file_parts)\n",
        "            process_all_files = False\n",
        "            print(f\"   ‚úÖ Set specific_file from sys.argv[2:] = '{specific_file}'\")\n",
        "            print(f\"   üìù File parts were: {file_parts}\")\n",
        "        else:\n",
        "            process_all_files = True\n",
        "            specific_file = None\n",
        "            print(f\"   üìã No specific file provided - will process ALL files in stage\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error parsing parameters, using defaults: {e}\")\n",
        "else:\n",
        "    print(f\"\\nüìã Not enough parameters provided ({len(sys.argv)}), using defaults.\")\n",
        "    print(f\"üìã Will process ALL files in default stage\")\n",
        "\n",
        "# Parameter validation and correction\n",
        "print(f\"\\nüîß Validating and fixing parameters...\")\n",
        "if not input_stage.startswith('@'):\n",
        "    print(f\"‚ö†Ô∏è WARNING: input_stage missing '@' prefix. Got: '{input_stage}'\")\n",
        "    input_stage = f\"@{input_stage}\"\n",
        "    print(f\"üîß Fixed: input_stage = '{input_stage}'\")\n",
        "\n",
        "if not output_stage.startswith('@'):\n",
        "    print(f\"‚ö†Ô∏è WARNING: output_stage missing '@' prefix. Got: '{output_stage}'\")\n",
        "    output_stage = f\"@{output_stage}\"\n",
        "    print(f\"üîß Fixed: output_stage = '{output_stage}'\")\n",
        "\n",
        "if specific_file and not specific_file.endswith('.pdf'):\n",
        "    print(f\"‚ö†Ô∏è WARNING: specific_file should be a PDF file. Got: '{specific_file}'\")\n",
        "\n",
        "print(f\"\\nüéØ FINAL PARAMETERS TO BE USED:\")\n",
        "print(f\"   Input Stage: '{input_stage}'\")\n",
        "print(f\"   Output Stage: '{output_stage}'\")\n",
        "if process_all_files:\n",
        "    print(f\"   Processing Mode: ALL FILES in input stage\")\n",
        "else:\n",
        "    print(f\"   Processing Mode: SINGLE FILE\")\n",
        "    print(f\"   Specific File: '{specific_file}'\")\n",
        "    print(f\"   File has spaces: {'yes' if ' ' in specific_file else 'no'}\")\n",
        "print(f\"   \" + \"=\"*50)\n",
        "\n",
        "# Get the active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "def setup_tracking_table():\n",
        "    \"\"\"\n",
        "    Create the PII redaction tracking table if it doesn't exist.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üìã Setting up tracking table...\")\n",
        "        \n",
        "        create_table_sql = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS PII_REDACTION_LOG (\n",
        "            LOG_ID NUMBER AUTOINCREMENT,\n",
        "            TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
        "            INPUT_STAGE STRING,\n",
        "            INPUT_FILE STRING,\n",
        "            OUTPUT_STAGE STRING,\n",
        "            STATUS STRING, -- 'SUBMITTED', 'COMPLETED', 'FAILED'\n",
        "            ERROR_MESSAGE STRING,\n",
        "            TEXT_LENGTH NUMBER,\n",
        "            PII_FOUND_COUNT NUMBER,\n",
        "            PII_ITEMS STRING, -- JSON array of PII items\n",
        "            REDACTIONS_MADE NUMBER,\n",
        "            OUTPUT_FILE STRING,\n",
        "            PROCESSING_TIME_SECONDS NUMBER,\n",
        "            WARNINGS STRING, -- JSON array of warnings\n",
        "            CONSTRAINT PK_PII_LOG PRIMARY KEY (LOG_ID)\n",
        "        )\n",
        "        \"\"\"\n",
        "        \n",
        "        session.sql(create_table_sql).collect()\n",
        "        print(f\"‚úÖ Tracking table PII_REDACTION_LOG ready\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to create tracking table: {e}\")\n",
        "        return False\n",
        "\n",
        "def log_processing_start(input_stage: str, input_file: str, output_stage: str) -> int:\n",
        "    \"\"\"\n",
        "    Log the start of processing and return the log_id for updates.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        insert_sql = f\"\"\"\n",
        "        INSERT INTO PII_REDACTION_LOG \n",
        "        (INPUT_STAGE, INPUT_FILE, OUTPUT_STAGE, STATUS)\n",
        "        VALUES \n",
        "        ('{input_stage.replace(\"'\", \"''\")}', \n",
        "         '{input_file.replace(\"'\", \"''\")}', \n",
        "         '{output_stage.replace(\"'\", \"''\")}', \n",
        "         'SUBMITTED')\n",
        "        \"\"\"\n",
        "        \n",
        "        session.sql(insert_sql).collect()\n",
        "        \n",
        "        # Get the log_id of the inserted record\n",
        "        get_id_sql = \"\"\"\n",
        "        SELECT MAX(LOG_ID) as LOG_ID \n",
        "        FROM PII_REDACTION_LOG \n",
        "        WHERE STATUS = 'SUBMITTED'\n",
        "        \"\"\"\n",
        "        \n",
        "        result = session.sql(get_id_sql).collect()\n",
        "        log_id = result[0][0] if result else None\n",
        "        \n",
        "        print(f\"üìù Started tracking with LOG_ID: {log_id}\")\n",
        "        return log_id\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to log processing start: {e}\")\n",
        "        return None\n",
        "\n",
        "def log_processing_result(log_id: int, results: dict, processing_time: float):\n",
        "    \"\"\"\n",
        "    Update the log with final processing results.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if log_id is None:\n",
        "            print(f\"‚ö†Ô∏è No log_id provided, skipping result logging\")\n",
        "            return\n",
        "            \n",
        "        status = 'COMPLETED' if results['success'] else 'FAILED'\n",
        "        error_msg = results.get('error', '').replace(\"'\", \"''\")\n",
        "        pii_items_json = json.dumps(results.get('pii_found', [])).replace(\"'\", \"''\")\n",
        "        warnings_json = json.dumps(results.get('warnings', [])).replace(\"'\", \"''\")\n",
        "        output_file = results.get('output_file', '').replace(\"'\", \"''\")\n",
        "        \n",
        "        update_sql = f\"\"\"\n",
        "        UPDATE PII_REDACTION_LOG \n",
        "        SET \n",
        "            STATUS = '{status}',\n",
        "            ERROR_MESSAGE = '{error_msg}',\n",
        "            TEXT_LENGTH = {results.get('extracted_text_length', 0)},\n",
        "            PII_FOUND_COUNT = {len(results.get('pii_found', []))},\n",
        "            PII_ITEMS = '{pii_items_json}',\n",
        "            REDACTIONS_MADE = {results.get('total_redactions', 0)},\n",
        "            OUTPUT_FILE = '{output_file}',\n",
        "            PROCESSING_TIME_SECONDS = {processing_time:.2f},\n",
        "            WARNINGS = '{warnings_json}'\n",
        "        WHERE LOG_ID = {log_id}\n",
        "        \"\"\"\n",
        "        \n",
        "        session.sql(update_sql).collect()\n",
        "        print(f\"üìù Updated tracking log {log_id} with status: {status}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to log processing result: {e}\")\n",
        "\n",
        "def get_all_pdf_files(stage_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Get all PDF files from the specified stage.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üìÅ Getting all PDF files from stage: {stage_path}\")\n",
        "        \n",
        "        # List files in the stage\n",
        "        list_query = f\"LIST {stage_path}\"\n",
        "        print(f\"üìù LIST query: {list_query}\")\n",
        "        \n",
        "        files_result = session.sql(list_query).collect()\n",
        "        print(f\"üìä Found {len(files_result)} total files in stage\")\n",
        "        \n",
        "        # Extract PDF file names from the result\n",
        "        pdf_files = []\n",
        "        for row in files_result:\n",
        "            file_path = row[0]  # The file path is typically in the first column\n",
        "            \n",
        "            # Extract just the filename from the full path\n",
        "            if '/' in file_path:\n",
        "                filename = file_path.split('/')[-1]\n",
        "            else:\n",
        "                filename = file_path\n",
        "            \n",
        "            # Only include PDF files\n",
        "            if filename.lower().endswith('.pdf'):\n",
        "                pdf_files.append(filename)\n",
        "                print(f\"   üìÑ Found PDF: '{filename}'\")\n",
        "        \n",
        "        print(f\"‚úÖ Total PDF files found: {len(pdf_files)}\")\n",
        "        return pdf_files\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error getting PDF files from stage: {e}\")\n",
        "        raise\n",
        "\n",
        "def check_file_exists(stage_path: str, file_name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Check if a file exists in the specified stage.\n",
        "    Enhanced to handle files with spaces and special characters.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üîç Checking if file exists: {stage_path}/{file_name}\")\n",
        "        \n",
        "        # List files in the stage and check if our file exists\n",
        "        list_query = f\"LIST {stage_path}\"\n",
        "        \n",
        "        files_result = session.sql(list_query).collect()\n",
        "        \n",
        "        # Extract file names from the result\n",
        "        existing_files = []\n",
        "        for row in files_result:\n",
        "            file_path = row[0]  # The file path is typically in the first column\n",
        "            \n",
        "            # Extract just the filename from the full path\n",
        "            if '/' in file_path:\n",
        "                filename = file_path.split('/')[-1]\n",
        "            else:\n",
        "                filename = file_path\n",
        "            existing_files.append(filename)\n",
        "        \n",
        "        # Check for exact match first\n",
        "        file_exists = file_name in existing_files\n",
        "        \n",
        "        # If not found, check for case-insensitive match\n",
        "        if not file_exists:\n",
        "            file_name_lower = file_name.lower()\n",
        "            for existing_file in existing_files:\n",
        "                if existing_file.lower() == file_name_lower:\n",
        "                    print(f\"üìù Found case-insensitive match: '{existing_file}' vs '{file_name}'\")\n",
        "                    file_exists = True\n",
        "                    break\n",
        "        \n",
        "        print(f\"‚úÖ File '{file_name}' exists: {file_exists}\")\n",
        "        return file_exists\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error checking file existence: {e}\")\n",
        "        return False\n",
        "\n",
        "def extract_text_from_pdf(stage_path: str, file_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from a PDF using Snowflake Cortex parse_document.\n",
        "    Enhanced to handle files with spaces and special characters.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üîç extract_text_from_pdf called with:\")\n",
        "        print(f\"   stage_path: '{stage_path}'\")\n",
        "        print(f\"   file_name: '{file_name}'\")\n",
        "        \n",
        "        # Validate inputs before building query\n",
        "        if not stage_path.startswith('@'):\n",
        "            raise ValueError(f\"Stage path must start with '@'. Got: '{stage_path}'\")\n",
        "        if not file_name.endswith('.pdf'):\n",
        "            raise ValueError(f\"File name must end with '.pdf'. Got: '{file_name}'\")\n",
        "        \n",
        "        # Remove @ symbol if present for the stage reference\n",
        "        stage_ref = stage_path.lstrip('@')\n",
        "        \n",
        "        # Properly escape file name for SQL (handles spaces and special characters)\n",
        "        escaped_file_name = file_name.replace(\"'\", \"''\")\n",
        "        \n",
        "        # Build query with proper escaping\n",
        "        parse_query = f\"\"\"\n",
        "            SELECT snowflake.cortex.parse_document(\n",
        "                @{stage_ref},\n",
        "                '{escaped_file_name}'\n",
        "            )\n",
        "        \"\"\"\n",
        "        \n",
        "        parsed_result = session.sql(parse_query).collect()\n",
        "        \n",
        "        if parsed_result and len(parsed_result) > 0:\n",
        "            json_string = parsed_result[0][0]\n",
        "            if json_string:\n",
        "                data = json.loads(json_string)\n",
        "                content = data.get(\"content\", \"No content found.\").replace('\\n', ' ')\n",
        "                print(f\"‚úÖ Successfully extracted {len(content)} characters\")\n",
        "                return content\n",
        "            else:\n",
        "                raise Exception(\"Parse result is empty or null\")\n",
        "        else:\n",
        "            raise Exception(\"No content extracted from PDF - empty result set\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to extract text from document: {e}\")\n",
        "        raise\n",
        "\n",
        "def detect_pii(text_content: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Detect PII elements in text using Snowflake Cortex AI.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not text_content or len(text_content.strip()) == 0:\n",
        "            print(f\"‚ö†Ô∏è No text content to analyze for PII\")\n",
        "            return []\n",
        "            \n",
        "        print(f\"üîç Analyzing {len(text_content)} characters for PII...\")\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "            Extract all PII from the text. PII includes names, phone numbers, emails, addresses, and unique URLs.\n",
        "            List each item. If none, state 'No PII detected'. Text: {text_content}\n",
        "        \"\"\"\n",
        "        pii_query = f\"\"\"\n",
        "            SELECT AI_COMPLETE(\n",
        "                model => 'claude-3-5-sonnet', \n",
        "                prompt => $${prompt}$$, \n",
        "                response_format => {{\n",
        "                    'type': 'json', \n",
        "                    'schema': {{\n",
        "                        'type': 'object', \n",
        "                        'properties': {{\n",
        "                            'pii_list': {{\n",
        "                                'type': 'array', \n",
        "                                'items': {{'type': 'string'}}\n",
        "                            }}\n",
        "                        }}\n",
        "                    }}\n",
        "                }}\n",
        "            ) as pii_results\n",
        "        \"\"\"\n",
        "        pii_results_df = session.sql(pii_query).to_pandas()\n",
        "        pii_output = pii_results_df['PII_RESULTS'][0]\n",
        "        pii_data = json.loads(pii_output)\n",
        "        pii_list = pii_data.get('pii_list', [])\n",
        "        print(f\"‚úÖ PII analysis complete: found {len(pii_list)} items\")\n",
        "        return pii_list\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to analyze PII: {e}\")\n",
        "        raise\n",
        "\n",
        "def redact_pii_from_pdf(pdf_path: str, pii_list: List[str]) -> Tuple[bytes, int]:\n",
        "    \"\"\"\n",
        "    Redacts PII from a PDF by finding the coordinates of each word, matching them against\n",
        "    the PII list, and then redacting the identified phrases.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üîç Opening PDF for redaction: {pdf_path}\")\n",
        "        doc = fitz.open(pdf_path)\n",
        "        total_redactions = 0\n",
        "        \n",
        "        # Clean up the PII list for efficient searching\n",
        "        pii_to_find = list(set(item.strip().lower() for item in pii_list if item.strip()))\n",
        "        \n",
        "        if not pii_to_find:\n",
        "            print(\"‚ö†Ô∏è PII list is empty, no redactions to perform.\")\n",
        "            return doc.tobytes(), 0\n",
        "\n",
        "        print(f\"üîç Searching for {len(pii_to_find)} unique PII elements across {len(doc)} pages...\")\n",
        "\n",
        "        # Iterate through each page of the PDF\n",
        "        for page_num, page in enumerate(doc):\n",
        "            redactions_on_page = 0\n",
        "            # Get all words on the page with their coordinates\n",
        "            words = page.get_text(\"words\")\n",
        "            \n",
        "            if not words:\n",
        "                continue\n",
        "\n",
        "            for pii_item in pii_to_find:\n",
        "                pii_words = pii_item.split()\n",
        "                if not pii_words:\n",
        "                    continue\n",
        "\n",
        "                # Search for sequences of words on the page that match the PII item\n",
        "                for i in range(len(words) - len(pii_words) + 1):\n",
        "                    phrase_to_check = \" \".join(words[j][4] for j in range(i, i + len(pii_words)))\n",
        "                    \n",
        "                    # Check for a case-insensitive match\n",
        "                    if phrase_to_check.lower() == pii_item:\n",
        "                        start_rect = fitz.Rect(words[i][:4])\n",
        "                        end_rect = fitz.Rect(words[i + len(pii_words) - 1][:4])\n",
        "                        redaction_rect = start_rect | end_rect\n",
        "                        \n",
        "                        page.add_redact_annot(redaction_rect, fill=(0, 0, 0))\n",
        "                        total_redactions += 1\n",
        "                        redactions_on_page += 1\n",
        "            \n",
        "            if redactions_on_page > 0:\n",
        "                print(f\"‚úÖ Marked {redactions_on_page} redactions on page {page_num + 1}.\")\n",
        "                # Apply redactions, which also removes the underlying text\n",
        "                page.apply_redactions(images=fitz.PDF_REDACT_IMAGE_PIXELS) \n",
        "\n",
        "        pdf_bytes = doc.tobytes()\n",
        "        doc.close()\n",
        "        print(f\"‚úÖ PDF redaction complete: {total_redactions} total redactions\")\n",
        "        \n",
        "        return pdf_bytes, total_redactions\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during PDF redaction: {e}\")\n",
        "        raise\n",
        "\n",
        "def safe_file_download(stage_path: str, file_name: str, temp_dir: str) -> str:\n",
        "    \"\"\"\n",
        "    Safely download a file with special handling for files with spaces.\n",
        "    Returns the local file path.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üì• Starting safe file download for: '{file_name}'\")\n",
        "        \n",
        "        local_file_path = os.path.join(temp_dir, file_name)\n",
        "        \n",
        "        # Method 1: Direct download\n",
        "        try:\n",
        "            download_result = session.file.get(f\"{stage_path}/{file_name}\", temp_dir)\n",
        "            if os.path.exists(local_file_path):\n",
        "                file_size = os.path.getsize(local_file_path)\n",
        "                print(f\"‚úÖ File downloaded successfully: {file_size} bytes\")\n",
        "                return local_file_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Standard download failed: {e}\")\n",
        "        \n",
        "        # Method 2: Try with URL encoding\n",
        "        try:\n",
        "            encoded_file_name = urllib.parse.quote(file_name)\n",
        "            download_result = session.file.get(f\"{stage_path}/{encoded_file_name}\", temp_dir)\n",
        "            \n",
        "            encoded_local_path = os.path.join(temp_dir, encoded_file_name)\n",
        "            if os.path.exists(encoded_local_path):\n",
        "                os.rename(encoded_local_path, local_file_path)\n",
        "                file_size = os.path.getsize(local_file_path)\n",
        "                print(f\"‚úÖ File downloaded successfully (encoded): {file_size} bytes\")\n",
        "                return local_file_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Encoded download failed: {e}\")\n",
        "        \n",
        "        # Method 3: SQL GET command\n",
        "        try:\n",
        "            escaped_file_name = file_name.replace(\"'\", \"''\")\n",
        "            get_sql = f\"\"\"\n",
        "            GET {stage_path}/'{escaped_file_name}' \n",
        "            FILE:///{temp_dir.replace(chr(92), '/')}/\n",
        "            \"\"\"\n",
        "            \n",
        "            result = session.sql(get_sql).collect()\n",
        "            \n",
        "            if os.path.exists(local_file_path):\n",
        "                file_size = os.path.getsize(local_file_path)\n",
        "                print(f\"‚úÖ File downloaded successfully (SQL GET): {file_size} bytes\")\n",
        "                return local_file_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è SQL GET download failed: {e}\")\n",
        "        \n",
        "        raise Exception(f\"All download methods failed for file '{file_name}'\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Safe file download failed: {e}\")\n",
        "        raise\n",
        "\n",
        "def safe_file_upload(local_file_path: str, stage_path: str, target_filename: str) -> bool:\n",
        "    \"\"\"\n",
        "    Safely upload a file with special handling for files with spaces.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üì§ Starting safe file upload for: '{target_filename}'\")\n",
        "        \n",
        "        if not os.path.exists(local_file_path):\n",
        "            raise Exception(f\"Local file not found: {local_file_path}\")\n",
        "        \n",
        "        file_size = os.path.getsize(local_file_path)\n",
        "        print(f\"üìä Local file size: {file_size} bytes\")\n",
        "        \n",
        "        # Method 1: Standard upload\n",
        "        try:\n",
        "            upload_result = session.file.put(local_file_path, stage_path, auto_compress=False, overwrite=True)\n",
        "            print(f\"‚úÖ File uploaded successfully\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Standard upload failed: {e}\")\n",
        "        \n",
        "        # Method 2: SQL PUT command\n",
        "        try:\n",
        "            put_sql = f\"\"\"\n",
        "            PUT FILE:///{local_file_path.replace(chr(92), '/')}\n",
        "            {stage_path}\n",
        "            AUTO_COMPRESS=FALSE\n",
        "            OVERWRITE=TRUE\n",
        "            \"\"\"\n",
        "            \n",
        "            result = session.sql(put_sql).collect()\n",
        "            print(f\"‚úÖ File uploaded successfully (SQL PUT)\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è SQL PUT upload failed: {e}\")\n",
        "        \n",
        "        raise Exception(f\"All upload methods failed for file '{target_filename}'\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Safe file upload failed: {e}\")\n",
        "        raise\n",
        "\n",
        "def process_single_pdf(input_stage: str, input_file: str, output_stage: str) -> dict:\n",
        "    \"\"\"\n",
        "    Process PII redaction for a single PDF file.\n",
        "    \"\"\"\n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    results = {\n",
        "        'input_file': input_file,\n",
        "        'success': False,\n",
        "        'extracted_text_length': 0,\n",
        "        'pii_found': [],\n",
        "        'total_redactions': 0,\n",
        "        'output_file': None,\n",
        "        'error': None,\n",
        "        'warnings': []\n",
        "    }\n",
        "    \n",
        "    # Log the start\n",
        "    log_id = log_processing_start(input_stage, input_file, output_stage)\n",
        "    \n",
        "    try:\n",
        "        print(f\"üöÄ Processing single file: '{input_file}'\")\n",
        "        \n",
        "        # Step 0: Check if input file exists\n",
        "        if not check_file_exists(input_stage, input_file):\n",
        "            error_msg = f\"Input file '{input_file}' not found in stage '{input_stage}'\"\n",
        "            print(f\"‚ùå {error_msg}\")\n",
        "            results['error'] = error_msg\n",
        "            return results\n",
        "        \n",
        "        # Step 1: Extract text from PDF\n",
        "        print(f\"\\nüìù Step 1: Extracting text from PDF...\")\n",
        "        extracted_text = extract_text_from_pdf(input_stage, input_file)\n",
        "        results['extracted_text_length'] = len(extracted_text)\n",
        "        print(f\"‚úÖ Extracted {len(extracted_text)} characters of text\")\n",
        "        \n",
        "        if len(extracted_text) < 10:\n",
        "            warning = f\"Very little text extracted ({len(extracted_text)} chars). File might be image-based or corrupted.\"\n",
        "            print(f\"‚ö†Ô∏è {warning}\")\n",
        "            results['warnings'].append(warning)\n",
        "        \n",
        "        # Step 2: Detect PII\n",
        "        print(f\"\\nüîç Step 2: Detecting PII elements...\")\n",
        "        pii_list = detect_pii(extracted_text)\n",
        "        results['pii_found'] = pii_list\n",
        "        print(f\"‚úÖ Found {len(pii_list)} PII elements\")\n",
        "        \n",
        "        if not pii_list:\n",
        "            print(f\"\\n‚ÑπÔ∏è No PII found - copying original file to output stage\")\n",
        "            with tempfile.TemporaryDirectory() as temp_dir:\n",
        "                try:\n",
        "                    local_input_path = safe_file_download(input_stage, input_file, temp_dir)\n",
        "                    output_filename = f\"redacted_{input_file}\"\n",
        "                    safe_file_upload(local_input_path, output_stage, output_filename)\n",
        "                    results['output_file'] = output_filename\n",
        "                    results['success'] = True\n",
        "                except Exception as e:\n",
        "                    error_msg = f\"Failed to copy file (no PII case): {str(e)}\"\n",
        "                    print(f\"‚ùå {error_msg}\")\n",
        "                    results['error'] = error_msg\n",
        "                    return results\n",
        "            return results\n",
        "        \n",
        "        # Step 3: Download PDF and redact PII\n",
        "        print(f\"\\nüñ§ Step 3: Redacting PII from PDF...\")\n",
        "        with tempfile.TemporaryDirectory() as temp_dir:\n",
        "            try:\n",
        "                local_input_path = safe_file_download(input_stage, input_file, temp_dir)\n",
        "                \n",
        "                # Redact PII\n",
        "                redacted_pdf_bytes, total_redactions = redact_pii_from_pdf(local_input_path, pii_list)\n",
        "                results['total_redactions'] = total_redactions\n",
        "                \n",
        "                # Save redacted PDF\n",
        "                output_filename = f\"redacted_{input_file}\"\n",
        "                local_output_path = os.path.join(temp_dir, output_filename)\n",
        "                \n",
        "                with open(local_output_path, 'wb') as f:\n",
        "                    f.write(redacted_pdf_bytes)\n",
        "                \n",
        "                # Upload to output stage\n",
        "                safe_file_upload(local_output_path, output_stage, output_filename)\n",
        "                results['output_file'] = output_filename\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_msg = f\"Failed during redaction process: {str(e)}\"\n",
        "                print(f\"‚ùå {error_msg}\")\n",
        "                results['error'] = error_msg\n",
        "                return results\n",
        "                \n",
        "        print(f\"\\n‚úÖ Successfully applied {total_redactions} redactions\")\n",
        "        results['success'] = True\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"Unexpected error processing '{input_file}': {str(e)}\"\n",
        "        print(f\"‚ùå {error_msg}\")\n",
        "        results['error'] = error_msg\n",
        "    \n",
        "    finally:\n",
        "        # Log the final results\n",
        "        processing_time = (datetime.now() - start_time).total_seconds()\n",
        "        log_processing_result(log_id, results, processing_time)\n",
        "    \n",
        "    return results\n",
        "\n",
        "def process_all_pdfs(input_stage: str, output_stage: str) -> dict:\n",
        "    \"\"\"\n",
        "    Process all PDF files in the input stage.\n",
        "    \"\"\"\n",
        "    overall_start_time = datetime.now()\n",
        "    \n",
        "    summary = {\n",
        "        'total_files': 0,\n",
        "        'successful': 0,\n",
        "        'failed': 0,\n",
        "        'files_processed': [],\n",
        "        'errors': []\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        print(f\"üöÄ Starting bulk processing of all PDFs in stage: {input_stage}\")\n",
        "        \n",
        "        # Get all PDF files\n",
        "        pdf_files = get_all_pdf_files(input_stage)\n",
        "        summary['total_files'] = len(pdf_files)\n",
        "        \n",
        "        if not pdf_files:\n",
        "            print(f\"‚ö†Ô∏è No PDF files found in stage: {input_stage}\")\n",
        "            return summary\n",
        "        \n",
        "        print(f\"üìã Found {len(pdf_files)} PDF files to process\")\n",
        "        \n",
        "        # Process each file\n",
        "        for i, pdf_file in enumerate(pdf_files, 1):\n",
        "            print(f\"\\n\" + \"=\"*60)\n",
        "            print(f\"üìÑ Processing file {i}/{len(pdf_files)}: '{pdf_file}'\")\n",
        "            print(\"=\"*60)\n",
        "            \n",
        "            try:\n",
        "                result = process_single_pdf(input_stage, pdf_file, output_stage)\n",
        "                \n",
        "                if result['success']:\n",
        "                    summary['successful'] += 1\n",
        "                    print(f\"‚úÖ Successfully processed: {pdf_file}\")\n",
        "                else:\n",
        "                    summary['failed'] += 1\n",
        "                    error_info = f\"Failed to process '{pdf_file}': {result.get('error', 'Unknown error')}\"\n",
        "                    summary['errors'].append(error_info)\n",
        "                    print(f\"‚ùå Failed to process: {pdf_file}\")\n",
        "                \n",
        "                summary['files_processed'].append({\n",
        "                    'file': pdf_file,\n",
        "                    'success': result['success'],\n",
        "                    'pii_found': len(result['pii_found']),\n",
        "                    'redactions': result['total_redactions'],\n",
        "                    'output_file': result.get('output_file'),\n",
        "                    'error': result.get('error')\n",
        "                })\n",
        "                \n",
        "            except Exception as e:\n",
        "                summary['failed'] += 1\n",
        "                error_info = f\"Exception processing '{pdf_file}': {str(e)}\"\n",
        "                summary['errors'].append(error_info)\n",
        "                print(f\"‚ùå Exception processing {pdf_file}: {e}\")\n",
        "        \n",
        "        # Print summary\n",
        "        processing_time = (datetime.now() - overall_start_time).total_seconds()\n",
        "        print(f\"\\n\" + \"=\"*60)\n",
        "        print(f\"üìä BULK PROCESSING SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Total files found: {summary['total_files']}\")\n",
        "        print(f\"Successfully processed: {summary['successful']}\")\n",
        "        print(f\"Failed: {summary['failed']}\")\n",
        "        print(f\"Success rate: {(summary['successful'] / summary['total_files'] * 100):.1f}%\")\n",
        "        print(f\"Total processing time: {processing_time:.2f} seconds\")\n",
        "        \n",
        "        if summary['errors']:\n",
        "            print(f\"\\n‚ùå Errors encountered:\")\n",
        "            for error in summary['errors']:\n",
        "                print(f\"   - {error}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"Failed during bulk processing: {str(e)}\"\n",
        "        print(f\"‚ùå {error_msg}\")\n",
        "        summary['errors'].append(error_msg)\n",
        "    \n",
        "    return summary\n",
        "\n",
        "# ========================================\n",
        "# MAIN EXECUTION LOGIC\n",
        "# ========================================\n",
        "\n",
        "# Setup tracking table\n",
        "setup_tracking_table()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîí FLEXIBLE PII REDACTION BATCH PROCESSOR\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Execute based on parameters\n",
        "if process_all_files:\n",
        "    print(f\"üöÄ MODE: Processing ALL PDF files in stage\")\n",
        "    print(f\"üìÇ Input Stage: {input_stage}\")\n",
        "    print(f\"üìÇ Output Stage: {output_stage}\")\n",
        "    \n",
        "    summary = process_all_pdfs(input_stage, output_stage)\n",
        "    \n",
        "    print(f\"\\nüéâ BULK PROCESSING COMPLETED!\")\n",
        "    print(f\"üìä Summary: {summary['successful']}/{summary['total_files']} files processed successfully\")\n",
        "    \n",
        "else:\n",
        "    print(f\"üöÄ MODE: Processing SINGLE file\")\n",
        "    print(f\"üìÇ Input Stage: {input_stage}\")\n",
        "    print(f\"üìÑ File: {specific_file}\")\n",
        "    print(f\"üìÇ Output Stage: {output_stage}\")\n",
        "    \n",
        "    result = process_single_pdf(input_stage, specific_file, output_stage)\n",
        "    \n",
        "    # Print detailed results for single file\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"üìä SINGLE FILE PROCESSING RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Input File: '{result['input_file']}'\")\n",
        "    print(f\"Success: {result['success']}\")\n",
        "    print(f\"Text Length: {result['extracted_text_length']} characters\")\n",
        "    print(f\"PII Found: {len(result['pii_found'])} items\")\n",
        "    if result['pii_found']:\n",
        "        for i, pii in enumerate(result['pii_found'], 1):\n",
        "            print(f\"  {i}. {pii}\")\n",
        "    print(f\"Total Redactions: {result['total_redactions']}\")\n",
        "    print(f\"Output File: {result['output_file']}\")\n",
        "    \n",
        "    if result['error']:\n",
        "        print(f\"\\nüö® ERROR: {result['error']}\")\n",
        "    \n",
        "    if result.get('warnings'):\n",
        "        print(f\"\\n‚ö†Ô∏è WARNINGS:\")\n",
        "        for warning in result['warnings']:\n",
        "            print(f\"   - {warning}\")\n",
        "    \n",
        "    if result['success']:\n",
        "        print(f\"\\nüéâ PROCESSING COMPLETED SUCCESSFULLY!\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå PROCESSING FAILED\")\n",
        "\n",
        "print(f\"\\nüìä Check PII_REDACTION_LOG table for detailed tracking:\")\n",
        "print(f\"üìù Query: SELECT * FROM PII_REDACTION_LOG ORDER BY TIMESTAMP DESC LIMIT 10;\")\n",
        "print(\"=\"*50)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
